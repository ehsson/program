from google.colab import drive
drive.mount("/content/drive")

import os
import sys
sys.path.append("/content/drive/MyDrive/#fastcampus")
drive_project_root = "/content/drive/MyDrive/#fastcampus"
!pip install -r "/content/drive/MyDrive/#fastcampus/requirements.txt"


import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from omegaconf import OmegaConf
from omegaconf import DictConfig
from datetime import datetime

import tensorflow as tf
import tensorflow_addons as tfa
!pip install wandb
!wandb login
import wandb


with mirrored_strategy.scope():
  # 데이터 셋 정의
  fashion_mnist = tf.keras.datasets.fashion_mnist
  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

  # normalization
  x_train = x_train / 255.0
  x_test = x_test / 255.0

  # train/val splits
  train_size = int(len(x_train) * 0.9)
  val_size = len(x_train) - train_size

  dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size = 1024)
  test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(buffer_size = 1024)

  train_dataset = dataset.take(train_size)
  val_dataset = dataset.skip(train_size)
  print(len(train_dataset), len(val_dataset), len(dataset), len(test_dataset))

  # dataloader 정의
  train_batch_size = 100
  val_batch_size = 10
  test_batch_size = 100

  train_dataloader = train_dataset.batch(train_batch_size, drop_remainder = True)
  val_dataloader = val_dataset.batch(val_batch_size, drop_remainder = True)
  test_dataloader = test_dataset.batch(test_batch_size, drop_remainder = True)

sample_example = next(iter(train_dataloader))
print(sample_example)


# plot figure
plt.figure(figsize = (10, 10))

for c in range(16):
  plt.subplot(4, 4, c + 1)
  plt.imshow(x_train[c].reshape(28, 28), cmap = 'gray')
plt.show()


class MLP(tf.keras.Model):
  def __init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int):
    super().__init__()
    self.flatten = tf.keras.layers.Flatten()
    self.linear1 = tf.keras.layers.Dense(input_dim = input_dim, units = h1_dim)
    self.linear2 = tf.keras.layers.Dense(units = h2_dim)
    self.linear3 = tf.keras.layers.Dense(units = out_dim)
    self.relu = tf.nn.relu

  def call(self, input, training = False):
    x = self.flatten(input)
    x = self.relu(self.linear1(x))
    x = self.relu(self.linear2(x))
    out = self.linear3(x)
    out = tf.nn.softmax(out)
    return out

  def train_step(self, data):
    images, labels = data

    with tf.GradientTape() as tape:
      outputs = self(images, training = True)
      preds = tf.argmax(outputs, 1)

      loss = self.compiled_loss(labels, outputs)

    # compute gradients
    trainable_vars = self.trainable_variables
    gradients = tape.gradient(loss, trainable_vars)

    # update weights
    self.optimizer.apply_gradients(zip(gradients, trainable_vars))

    # update metrics
    self.compiled_metrics.update_state(labels, preds)

    # return a dict mapping metrics names to current values
    logs = {m.name: m.result() for m in self.metrics}
    return logs

  def test_step(self, data):
    images, labels = data
    outputs = self(images, training = False)
    preds = tf.argmax(outputs, 1)
    loss = self.compiled_loss(labels, outputs)

    # update metrics
    self.compiled_metrics.update_state(labels, preds)

    # return a dict mapping metrics names to current values
    logs = {m.name: m.result() for m in self.metrics}
    return logs



class MLPWithDropout(tf.keras.Model):
  def __init__(self, input_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):
    super().__init__()
    self.flatten = tf.keras.layers.Flatten()
    self.linear1 = tf.keras.layers.Dense(input_dim = input_dim, units = h1_dim)
    self.linear2 = tf.keras.layers.Dense(units = h2_dim)
    self.linear3 = tf.keras.layers.Dense(units = out_dim)
    self.dropout = tf.keras.layers.Dropout(dropout_prob)
    self.relu = tf.nn.relu

  def call(self, input, training = False):
    x = self.flatten(input)
    x = self.relu(self.linear1(x))
    x = self.dropout(x, training = training)
    x = self.relu(self.linear2(x))
    x = self.dropout(x, training = training)
    out = self.linear3(x)
    out = tf.nn.softmax(out)
    return out

  def train_step(self, data):
    images, labels = data

    with tf.GradientTape() as tape:
      outputs = self(images, training = True)
      preds = tf.argmax(outputs, 1)

      loss = self.compiled_loss(labels, outputs)

    # compute gradients
    trainable_vars = self.trainable_variables
    gradients = tape.gradient(loss, trainable_vars)

    # update weights
    self.optimizer.apply_gradients(zip(gradients, trainable_vars))

    # update metrics
    self.compiled_metrics.update_state(labels, preds)

    # return a dict mapping metrics names to current values
    logs = {m.name: m.result() for m in self.metrics}
    return logs

  def test_step(self, data):
    images, labels = data
    outputs = self(images, training = False)
    preds = tf.argmax(outputs, 1)
    loss = self.compiled_loss(labels, outputs)

    # update metrics
    self.compiled_metrics.update_state(labels, preds)

    # return a dict mapping metrics names to current values
    logs = {m.name: m.result() for m in self.metrics}
    return logs   
    
    

_cnn_cfg: dict = {
    "layer_1": {
        "conv2d_filters": 32,
        "conv2d_kernel_size": [3, 3],
        "conv2d_strides": [1, 1],
        "conv2d_padding": "same",
        "maxpool2d_pool_size": [2, 2],
        "maxpool2d_strides": [2, 2],
        "maxpool2d_padding": "valid"
    },
    "layer_2": {
        "conv2d_filters": 64,
        "conv2d_kernel_size": [3, 3],
        "conv2d_strides": [1, 1],
        "conv2d_padding": "valid",
        "maxpool2d_pool_size": [2, 2],
        "maxpool2d_strides": [1, 1],
        "maxpool2d_padding": "valid"
    },
    "fc_1": {"units": 512},
    "fc_2": {"units": 128},
    "fc_3": {"units": 10},
    "dropout_prob": 0.25
}

_cnn_cfg = OmegaConf.create(_cnn_cfg)
print(OmegaConf.to_yaml(_cnn_cfg))

class ConvBatchNormMaxPool(tf.keras.layers.Layer):
    def __init__(
            self,
            conv2d_filters,
            conv2d_kernel_size,
            conv2d_strides,
            conv2d_padding,
            maxpool2d_pool_size,
            maxpool2d_strides,
            maxpool2d_padding
        ):
        super().__init__()
        self.conv2d = tf.keras.layers.Conv2D(
            filters = conv2d_filters,
            kernel_size = conv2d_kernel_size,
            strides = conv2d_strides,
            padding = conv2d_padding
        )
        self.batchnorm = tf.keras.layers.BatchNormalization()
        self.maxpool2d = tf.keras.layers.MaxPool2D(
            pool_size = maxpool2d_pool_size,
            strides = maxpool2d_strides,
            padding = maxpool2d_padding
        )

    def call(self, input):
        """Conv2D -> BatchNormalization -> Activation -> MaxPooling"""
        x = self.conv2d(input)
        x = self.batchnorm(x)
        x = tf.keras.activations.relu(x)
        out = self.maxpool2d(x)
        return out

class CNN(tf.keras.Model):
    def __init__(self, cfg: DictConfig = _cnn_cfg):
        super().__init__()
        self.layer1 = ConvBatchNormMaxPool(
            cfg.layer_1.conv2d_filters,
            cfg.layer_1.conv2d_kernel_size,
            cfg.layer_1.conv2d_strides,
            cfg.layer_1.conv2d_padding,
            cfg.layer_1.maxpool2d_pool_size,
            cfg.layer_1.maxpool2d_strides,
            cfg.layer_1.maxpool2d_padding
        )
        self.layer2 = ConvBatchNormMaxPool(
            cfg.layer_2.conv2d_filters,
            cfg.layer_2.conv2d_kernel_size,
            cfg.layer_2.conv2d_strides,
            cfg.layer_2.conv2d_padding,
            cfg.layer_2.maxpool2d_pool_size,
            cfg.layer_2.maxpool2d_strides,
            cfg.layer_2.maxpool2d_padding
        )

        self.flatten = tf.keras.layers.Flatten()
        self.fc1 = tf.keras.layers.Dense(cfg.fc_1.units)
        self.fc2 = tf.keras.layers.Dense(cfg.fc_2.units)
        self.fc3 = tf.keras.layers.Dense(cfg.fc_3.units)
        self.dropout = tf.keras.layers.Dropout(cfg.dropout_prob)

    def call(self, input, training = False):
        input = tf.expand_dims(input, -1) # [B X 28 X 28 X 1]
        x = self.layer1(input)
        x = self.layer2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.dropout(x, training = training)
        x = self.fc2(x)
        out = self.fc3(x)
        out = tf.nn.softmax(out)
        return out

    def train_step(self, data):
        images, labels = data

        with tf.GradientTape() as tape:
            outputs = self(images, training = True)
            preds = tf.argmax(outputs, 1)

            loss = self.compiled_loss(labels, outputs)

        # compute gradients
        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)

        # update weights
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        # update metrics
        self.compiled_metrics.update_state(labels, preds)

        # return a dict mapping metrics names to current values
        logs = {m.name: m.result() for m in self.metrics}
        return logs

    def test_step(self, data):
        images, labels = data
        outputs = self(images, training = False)
        preds = tf.argmax(outputs, 1)
        loss = self.compiled_loss(labels, outputs)

        # update metrics
        self.compiled_metrics.update_state(labels, preds)

        # return a dict mapping metrics names to current values
        logs = {m.name: m.result() for m in self.metrics}
        return logs   



# learning rate scheduler 구현
class LinearWarmLRScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, lr_peak: float, warmup_end_steps: int):
        super().__init__()
        self.lr_peak= lr_peak
        self.warmup_end_steps = warmup_end_steps

    def __call__(self, step):
        step_float = tf.cast(step, tf.float32)
        warmup_end_steps = tf.cast(self.warmup_end_steps, tf.float32)
        lr_peak = tf.cast(self.lr_peak, tf.float32)

        return tf.cond(
            step_float < warmup_end_steps,
            lambda: lr_peak * (tf.math.maximum(step_float, 1) / warmup_end_steps),
            lambda: lr_peak
        )
        
        

a = LinearWarmLRScheduler(lr_peak = 1e-3, warmup_end_steps = 1000)
a(0)



from tensorflow.python.framework import ops
from tensorflow.python.keras import backend_config
from tensorflow.python.keras.optimizer_v2 import optimizer_v2
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import state_ops

class AdamP(tf.keras.optimizers.Optimizer):
    """Code is from https://github.com/taki0112/AdamP-Tensorflow/blob/master/adamp_tf.py with modifications"""
    _HAS_AGGREGATE_GRAD = True

    def __init__(self,
                 learning_rate=0.001,
                 beta_1=0.9,
                 beta_2=0.999,
                 epsilon=1e-8,
                 weight_decay=0.0,
                 delta=0.1, wd_ratio=0.1, nesterov=False,
                 name='AdamP',
                 **kwargs):

        super(AdamP, self).__init__(name, **kwargs)
        self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))
        self._set_hyper('beta_1', beta_1)
        self._set_hyper('beta_2', beta_2)
        self._set_hyper('delta', delta)
        self._set_hyper('wd_ratio', wd_ratio)

        self.epsilon = epsilon or backend_config.epsilon()
        self.weight_decay = weight_decay
        self.nesterov = nesterov

    def _create_slots(self, var_list):
        # Create slots for the first and second moments.
        # Separate for-loops to respect the ordering of slot variables from v1.
        for var in var_list:
            self.add_slot(var, 'm')
        for var in var_list:
            self.add_slot(var, 'v')
        for var in var_list:
            self.add_slot(var, 'p')

    def _prepare_local(self, var_device, var_dtype, apply_state):
        super(AdamP, self)._prepare_local(var_device, var_dtype, apply_state)

        local_step = math_ops.cast(self.iterations + 1, var_dtype)
        beta_1_t = array_ops.identity(self._get_hyper('beta_1', var_dtype))
        beta_2_t = array_ops.identity(self._get_hyper('beta_2', var_dtype))
        beta_1_power = math_ops.pow(beta_1_t, local_step)
        beta_2_power = math_ops.pow(beta_2_t, local_step)

        lr = apply_state[(var_device, var_dtype)]['lr_t']
        bias_correction1 = 1 - beta_1_power
        bias_correction2 = 1 - beta_2_power

        delta = array_ops.identity(self._get_hyper('delta', var_dtype))
        wd_ratio = array_ops.identity(self._get_hyper('wd_ratio', var_dtype))

        apply_state[(var_device, var_dtype)].update(
            dict(
                lr=lr,
                epsilon=ops.convert_to_tensor_v2(self.epsilon, var_dtype),
                weight_decay=ops.convert_to_tensor_v2(self.weight_decay, var_dtype),
                beta_1_t=beta_1_t,
                beta_1_power=beta_1_power,
                one_minus_beta_1_t=1 - beta_1_t,
                beta_2_t=beta_2_t,
                beta_2_power=beta_2_power,
                one_minus_beta_2_t=1 - beta_2_t,
                bias_correction1=bias_correction1,
                bias_correction2=bias_correction2,
                delta=delta,
                wd_ratio=wd_ratio))

    def set_weights(self, weights):
        params = self.weights
        # If the weights are generated by Keras V1 optimizer, it includes vhats
        # optimizer has 2x + 1 variables. Filter vhats out for compatibility.
        num_vars = int((len(params) - 1) / 2)
        if len(weights) == 3 * num_vars + 1:
            weights = weights[:len(params)]
        super(AdamP, self).set_weights(weights)

    def _resource_apply_dense(self, grad, var, apply_state=None):
        var_device, var_dtype = var.device, var.dtype.base_dtype
        coefficients = ((apply_state or {}).get((var_device, var_dtype))
                        or self._fallback_apply_state(var_device, var_dtype))

        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, 'm')
        m_scaled_g_values = grad * coefficients['one_minus_beta_1_t']
        m_t = state_ops.assign(m, m * coefficients['beta_1_t'] + m_scaled_g_values, use_locking=self._use_locking)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, 'v')
        v_scaled_g_values = (grad * grad) * coefficients['one_minus_beta_2_t']
        v_t = state_ops.assign(v, v * coefficients['beta_2_t'] + v_scaled_g_values, use_locking=self._use_locking)

        denorm = (math_ops.sqrt(v_t) / math_ops.sqrt(coefficients['bias_correction2'])) + coefficients['epsilon']
        step_size = coefficients['lr'] / coefficients['bias_correction1']

        if self.nesterov:
            perturb = (coefficients['beta_1_t'] * m_t + coefficients['one_minus_beta_1_t'] * grad) / denorm
        else:
            perturb = m_t / denorm

        # Projection
        wd_ratio = 1
        if len(var.shape) > 1:
            perturb, wd_ratio = self._projection(var, grad, perturb, coefficients['delta'], coefficients['wd_ratio'], coefficients['epsilon'])

        # Weight decay

        if self.weight_decay > 0:
            var = state_ops.assign(var, var * (1 - coefficients['lr'] * coefficients['weight_decay'] * wd_ratio), use_locking=self._use_locking)

        var_update = state_ops.assign_sub(var, step_size * perturb, use_locking=self._use_locking)

        return control_flow_ops.group(*[var_update, m_t, v_t])


    def _resource_apply_sparse(self, grad, var, indices, apply_state=None):

        var_device, var_dtype = var.device, var.dtype.base_dtype
        coefficients = ((apply_state or {}).get((var_device, var_dtype))
                        or self._fallback_apply_state(var_device, var_dtype))
        """
        Adam
        """
        # m_t = beta1 * m + (1 - beta1) * g_t
        m = self.get_slot(var, 'm')
        m_scaled_g_values = grad * coefficients['one_minus_beta_1_t']
        m_t = state_ops.assign(m, m * coefficients['beta_1_t'],
                               use_locking=self._use_locking)
        with ops.control_dependencies([m_t]):
            m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)

        # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)
        v = self.get_slot(var, 'v')
        v_scaled_g_values = (grad * grad) * coefficients['one_minus_beta_2_t']
        v_t = state_ops.assign(v, v * coefficients['beta_2_t'],
                               use_locking=self._use_locking)
        with ops.control_dependencies([v_t]):
            v_t = self._resource_scatter_add(v, indices, v_scaled_g_values)

        denorm = (math_ops.sqrt(v_t) / math_ops.sqrt(coefficients['bias_correction2'])) + coefficients['epsilon']
        step_size = coefficients['lr'] / coefficients['bias_correction1']

        if self.nesterov:
            p_scaled_g_values = grad * coefficients['one_minus_beta_1_t']
            perturb = m_t * coefficients['beta_1_t']
            perturb = self._resource_scatter_add(perturb, indices, p_scaled_g_values) / denorm

        else:
            perturb = m_t / denorm

        # Projection
        wd_ratio = 1
        if len(var.shape) > 1:
            perturb, wd_ratio = self._projection(var, grad, perturb, coefficients['delta'], coefficients['wd_ratio'], coefficients['epsilon'])

        # Weight decay
        if self.weight_decay > 0:
            var = state_ops.assign(var, var * (1 - coefficients['lr'] * coefficients['weight_decay'] * wd_ratio), use_locking=self._use_locking)

        var_update = state_ops.assign_sub(var, step_size * perturb, use_locking=self._use_locking)

        return control_flow_ops.group(*[var_update, m_t, v_t])

    def _channel_view(self, x):
        return array_ops.reshape(x, shape=[x.shape[0], -1])

    def _layer_view(self, x):
        return array_ops.reshape(x, shape=[1, -1])

    def _cosine_similarity(self, x, y, eps, view_func):
        x = view_func(x)
        y = view_func(y)

        x_norm = math_ops.euclidean_norm(x, axis=-1) + eps
        y_norm = math_ops.euclidean_norm(y, axis=-1) + eps
        dot = math_ops.reduce_sum(x * y, axis=-1)

        return math_ops.abs(dot) / x_norm / y_norm

    def _projection(self, var, grad, perturb, delta, wd_ratio, eps):
        # channel_view
        cosine_sim = self._cosine_similarity(grad, var, eps, self._channel_view)
        cosine_max = math_ops.reduce_max(cosine_sim)
        compare_val = delta / math_ops.sqrt(math_ops.cast(self._channel_view(var).shape[-1], dtype=delta.dtype))

        perturb, wd = control_flow_ops.cond(pred=cosine_max < compare_val,
                                            true_fn=lambda : self.channel_true_fn(var, perturb, wd_ratio, eps),
                                            false_fn=lambda : self.channel_false_fn(var, grad, perturb, delta, wd_ratio, eps))

        return perturb, wd

    def channel_true_fn(self, var, perturb, wd_ratio, eps):
        expand_size = [-1] + [1] * (len(var.shape) - 1)
        var_n = var / (array_ops.reshape(math_ops.euclidean_norm(self._channel_view(var), axis=-1), shape=expand_size) + eps)
        perturb -= var_n * array_ops.reshape(math_ops.reduce_sum(self._channel_view(var_n * perturb), axis=-1), shape=expand_size)
        wd = wd_ratio

        return perturb, wd

    def channel_false_fn(self, var, grad, perturb, delta, wd_ratio, eps):
        cosine_sim = self._cosine_similarity(grad, var, eps, self._layer_view)
        cosine_max = math_ops.reduce_max(cosine_sim)
        compare_val = delta / math_ops.sqrt(math_ops.cast(self._layer_view(var).shape[-1], dtype=delta.dtype))

        perturb, wd = control_flow_ops.cond(cosine_max < compare_val,
                                              true_fn=lambda : self.layer_true_fn(var, perturb, wd_ratio, eps),
                                              false_fn=lambda : self.identity_fn(perturb))

        return perturb, wd

    def layer_true_fn(self, var, perturb, wd_ratio, eps):
        expand_size = [-1] + [1] * (len(var.shape) - 1)
        var_n = var / (array_ops.reshape(math_ops.euclidean_norm(self._layer_view(var), axis=-1), shape=expand_size) + eps)
        perturb -= var_n * array_ops.reshape(math_ops.reduce_sum(self._layer_view(var_n * perturb), axis=-1), shape=expand_size)
        wd = wd_ratio

        return perturb, wd

    def identity_fn(self, perturb):
        wd = 1.0

        return perturb, wd

    def get_config(self):
        config = super(AdamP, self).get_config()
        config.update({
            'learning_rate': self._serialize_hyperparameter('learning_rate'),
            'beta_1': self._serialize_hyperparameter('beta_1'),
            'beta_2': self._serialize_hyperparameter('beta_2'),
            'delta': self._serialize_hyperparameter('delta'),
            'wd_ratio': self._serialize_hyperparameter('wd_ratio'),
            'epsilon': self.epsilon,
            'weight_decay': self.weight_decay,
            'nesterov': self.nesterov
        })
        return config
 
 
 
 # 모델 정의
n_class = 10
max_epoch = 50

with mirrored_strategy.scope():
  #model = MLP(28 * 28 * 1, 128, 64, n_class)
  #model = MLPWithDropout(28 * 28 * 1, 128, 64, n_class, dropout_prob = 0.3)
  model = CNN()
  model_name = type(model).__name__

  # define loss
  loss_function = tf.losses.SparseCategoricalCrossentropy()

  # define optimizer
  lr = 1e-3
  #scheduler = None
  scheduler = LinearWarmLRScheduler(lr, 1500)
  scheduler_name = type(scheduler).__name__ if scheduler is not None else "no_scheduler"

  if scheduler is None:
      scheduler = lr

  #optimizer = tf.optimizers.Adam(learning_rate = scheduler)
  #optimizer = tf.optimizers.SGD(learning_rate = scheduler)
  optimizer = tfa.optimizers.RectifiedAdam(learning_rate = scheduler)
  #optimizer = AdamP(learning_rate = scheduler)
  optimizer_name = type(optimizer).__name__

  model.compile(
      loss = loss_function,
      optimizer = optimizer,
      metrics = [tf.keras.metrics.Accuracy()],
  )

  model.build((1, 28, 28))
model.summary()


# define logging & callbacks
log_interval = 100
run_name = f"{datetime.now()}-{model_name}-{optimizer_name}-optim-{lr}_lr_with_{scheduler_name}"
run_dirname = "dnn-tutorial-fashion-mnist-runs-tf"
log_dir = os.path.join(drive_project_root, 'runs', run_dirname, run_name)

tb_callback = tf.keras.callbacks.TensorBoard(
    log_dir, update_freq = log_interval
)

early_stop_callback = tf.keras.callbacks.EarlyStopping(patience = 3, verbose = True)

# wandb setup
project_name= "fastcampus_fashion_mnist_tutorials_tf"
run_tags = [project_name]
wandb.init(
    project= project_name,
    name = run_name,
    tags = run_tags,
    config = {
        "lr": lr,
        "model_name": model_name,
        "optimizer_name": optimizer_name,
        "scheduler_name": scheduler_name,
    },
    reinit = True,
    sync_tensorboard = True
)



%load_ext tensorboard
%tensorboard --logdir /content/drive/MyDrive/\#fastcampus/runs/

model.fit(
    train_dataloader,
    validation_data = val_dataloader,
    epochs = max_epoch,
    callbacks = [tb_callback, early_stop_callback]
)


model.evaluate(test_dataloader)
test_labels_list = []
test_preds_list = []
test_outputs_list = []

for i, (test_images, test_labels) in enumerate(tqdm(test_dataloader, position = 0, leave = True, desc = "testing")):
  with mirrored_strategy.scope():
    test_outputs = model(test_images)
  test_preds = tf.argmax(test_outputs, 1)

  final_outs = test_outputs.numpy()
  test_outputs_list.extend(final_outs)
  test_preds_list.extend(test_preds.numpy())
  test_labels_list.extend(test_labels.numpy())

test_preds_list = np.array(test_preds_list)
test_labels_list = np.array(test_labels_list)

test_accuracy = np.mean(test_preds_list == test_labels_list)
print(f"\nacc: {test_accuracy * 100}%")


# ROC curve
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

fpr = {}
tpr = {}
thresh = {}
n_class = 10

for i in range(n_class):
  fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, np.array(test_outputs_list)[:, i], pos_label = i)

# plot
for i in range(n_class):
  plt.plot(fpr[i], tpr[i], linestyle = "--", label = f"Class {i} vs Rest")

plt.title("Multi-class ROC curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc = "best")
plt.show()

auc_score = roc_auc_score(test_labels_list, test_outputs_list, multi_class = "ovo", average = 'macro')
print(f"auc_score: {auc_score}")
